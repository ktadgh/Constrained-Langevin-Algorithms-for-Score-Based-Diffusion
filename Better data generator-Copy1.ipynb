{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd24f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541459a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd.functional import jacobian\n",
    "from tqdm import notebook, tqdm\n",
    "import random\n",
    "import torch.multiprocessing\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c235a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ea783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf03575",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a6a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba69f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def G(gs):\n",
    "    '''\n",
    "    :param gs: a list of tensor functions\n",
    "    :return: a function sending a tensor to the stacked matrix of the functions of that tensor\n",
    "    '''\n",
    "    def G_gs(tensor):\n",
    "        x = torch.squeeze(tensor)\n",
    "        # print(\"Function input: \",tensor) # checking the input for debugging\n",
    "        # print(\"Function output:\" , torch.stack([g(tensor) for g in gs],0))\n",
    "        return torch.stack([g(x) for g in gs], 0)\n",
    "\n",
    "    return G_gs\n",
    "\n",
    "@torch.compile(mode = \"max-autotune\")\n",
    "def J(gs, x):\n",
    "    '''Returns the Jacobian evaluated at x for a list gs of constraint functions'''\n",
    "    return jacobian(G(gs), torch.squeeze(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7268d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def rattle_step(x, v1, h, M, gs, e):\n",
    "    '''\n",
    "    Defining a function to take a step in the position, velocity form.\n",
    "    g should be a vector-valued function of constraints.\n",
    "    :return: x_1, v_1\n",
    "    '''\n",
    "\n",
    "    M1 =  torch.inverse(M)\n",
    "\n",
    "    G1 = G(gs)\n",
    "\n",
    "\n",
    "    DV = torch.zeros_like(x)\n",
    "\n",
    "    #DV[-1] = 10  # leaving this out for g-BAOAB\n",
    "    DV_col = DV.reshape(-1, 1)\n",
    "\n",
    "    x_col = x.reshape(-1, 1)\n",
    "    v1_col = v1.reshape(-1, 1)\n",
    "\n",
    "    # doing Newton-Raphson iterations\n",
    "    iters = 0\n",
    "    x2 = x_col + h * v1_col - 0.5*(h**2)* M1 @ DV_col\n",
    "    Q_col = x2\n",
    "    Q = torch.squeeze(Q_col)\n",
    "    J1 = J(gs, torch.squeeze(x_col))\n",
    "\n",
    "    #print(\"RATTLE\")\n",
    "    #while torch.any(torch.abs(G1(Q)) > e):\n",
    "    for iters in range(3):\n",
    "        J2 = J(gs, torch.squeeze(Q))\n",
    "        R = J2 @ M1 @ J1.t()\n",
    "        dL = torch.inverse(R) @ G1(Q)\n",
    "        #print(f\"Q = {Q}\")\n",
    "        Q=Q- M1 @ J1.t() @ dL\n",
    "    #print(\"CONVERGED\")\n",
    "    #print(f\"Updating v1_col, Jacobian {J(gs,torch.squeeze(x_col))}\")\n",
    "    #print(f\"Updating v1_col, Jacobian^T {J(gs,torch.squeeze(x_col)).t()}\")\n",
    "\n",
    "    # half step for velocity\n",
    "    Q_col = Q.reshape(-1,1)\n",
    "    v1_half = (Q_col - x_col)/h\n",
    "    x_col = Q_col\n",
    "    J1 = J(gs, torch.squeeze(x_col))\n",
    "\n",
    "    # getting the level\n",
    "    J2 = J(gs, torch.squeeze(Q))\n",
    "    P = J1 @ M1 @ J1.t()\n",
    "    T = J1 @ (2/h * v1_half - M1 @ DV_col)\n",
    "\n",
    "    #solving the linear system\n",
    "    L = torch.linalg.solve(P,T)\n",
    "\n",
    "    v1_col = v1_half - h/2 * DV_col - h/2 * J2.t()@L\n",
    "\n",
    "\n",
    "    # print(f\"Error = {G1(x_col + h*( v1_col + h/2 * torch.inverse(M) @ J1.reshape(-1,1) @ lam))}\")\n",
    "    # # updating v\n",
    "    # print(f\"lam = {lam}\")\n",
    "    # print(f\"Updating v1_col, Jacobian^T {J(gs,torch.squeeze(x_col)).t}\")\n",
    "\n",
    "    return torch.squeeze(x_col), torch.squeeze(v1_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4109e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def gBAOAB_step_exact(q_init,p_init,F, gs, h,M, gamma, k, kr,e):\n",
    "    # setting up variables\n",
    "    M1 = torch.inverse(M)\n",
    "    R = torch.randn(len(q_init))\n",
    "    p = p_init\n",
    "    q = q_init\n",
    "    a2 = torch.exp(torch.tensor(-gamma*h))\n",
    "    b2 = torch.sqrt(k*(1-a2**(2)))\n",
    "\n",
    "    # doing the initial p-update\n",
    "    J1 = J(gs,torch.squeeze(q))\n",
    "    G = J1\n",
    "    L1 = torch.eye(len(q_init)) - torch.transpose(G,0,1) @ torch.inverse(G@ M1@ torch.transpose(G,0,1)) @ G @ M1\n",
    "    p =p-  h/2 * L1 @ F(q)\n",
    "\n",
    "\n",
    "    # doing the first RATTLE step\n",
    "    for i in range(kr):\n",
    "      q, p = rattle_step(q, p, h/2*kr, M, gs, e)\n",
    "\n",
    "\n",
    "    # the second p-update - (O-step in BAOAB)\n",
    "    J2 = J(gs,torch.squeeze(q))\n",
    "    G = J2\n",
    "    L2 = torch.eye(len(q_init)) - torch.transpose(G,0,1) @ torch.inverse(G@ M1@ torch.transpose(G,0,1)) @ G @ M1\n",
    "    p = a2* p + b2* M**(1/2) @L2 @ M**(1/2) @ R\n",
    "\n",
    "    # doing the second RATTLE step\n",
    "    for i in range(kr):\n",
    "      q, p = rattle_step(q, p, h/2*kr, M, gs, e)\n",
    "\n",
    "\n",
    "    # the final p update\n",
    "    J3= J(gs,torch.squeeze(q))\n",
    "    G = J3\n",
    "    L3 = torch.eye(len(q_init)) - torch.transpose(G,0,1) @ torch.inverse(G@ M1@ torch.transpose(G,0,1)) @ G @ M1\n",
    "    p = p-  h/2 * L3 @ F(q)\n",
    "\n",
    "    return q,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b84f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def gBAOAB_integrator(q_init,p_init,F, gs, h,M, gamma, k, steps,kr,e):\n",
    "    positions = []\n",
    "    velocities = []\n",
    "    q = q_init\n",
    "    p = p_init\n",
    "    for i in range(steps):\n",
    "        q, p = gBAOAB_step_exact(q,p, F,gs, h,M, gamma, k,kr,e)\n",
    "        positions.append(q)\n",
    "        velocities.append(p)\n",
    "\n",
    "    return positions, velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c485d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def multi_gBAOAB_integrator(q_inits,p_inits,F, gs, h,M, gamma, k,ts,kr,e):\n",
    "    positions = []\n",
    "    velocities = []\n",
    "    for ind in len(q_inits):\n",
    "      q = q_inits[i]\n",
    "      p = p_inits[i]\n",
    "      steps = int(ts[i]//h)\n",
    "      for i in range(steps):\n",
    "        q, p = gBAOAB_step_exact(q,p, F,gs, h,M, gamma, k,kr,e)\n",
    "      positions.append(q)\n",
    "      velocities.append(p)\n",
    "\n",
    "    return torch.stack(positions), torch.stack(velocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f906ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bones2 = [\n",
    "    (1, 2),\n",
    "    (1, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 6),\n",
    "    (1, 7),\n",
    "    (7, 8),\n",
    "    (8, 9),\n",
    "    (9, 10),\n",
    "    (11, 12),\n",
    "    (12, 13),\n",
    "    (13, 14),\n",
    "    (15, 16),\n",
    "    (16, 17),\n",
    "    (17, 18),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78d5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def length_constraint(i,j, xinit):\n",
    "    init = torch.squeeze(xinit)\n",
    "    def constraint_fn(y):\n",
    "        x = torch.squeeze(y) # will need to change for batched data\n",
    "        return (x[3*i]- x[3*j])**2 +(x[3*i+1]- x[3*j+1])**2 + (x[3*i+2]- x[3*j+2])**2 - ((init[3*i]- init[3*j])**2 +(init[3*i+1]- init[3*j+1])**2 + (init[3*i+2]- init[3*j+2])**2)\n",
    "    return constraint_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2f8164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def length_constraint_2(i, xinit):\n",
    "    init = torch.squeeze(xinit)\n",
    "    def constraint_fn(y):\n",
    "        x = torch.squeeze(y)\n",
    "        return (x[3*i]- 0)**2 +(x[3*i+1]- 0)**2 + (x[3*i+2]- 2)**2 - ((init[3*i]- 0)**2 +(init[3*i+1]- 0)**2 + (init[3*i+2]- 2)**2)\n",
    "    return constraint_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809eec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def cotangent_projection(gs):\n",
    "    def proj(x):\n",
    "        G = J(gs,x)\n",
    "        M = torch.eye(G.size()[1])\n",
    "        L= torch.eye(G.size()[1]) - G.T @ torch.inverse(G @ M @ G.T) @ G @ torch.inverse(M)\n",
    "        return L\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a984c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"\n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed\n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * torch.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e0c4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model.\"\"\"\n",
    "\n",
    "\n",
    "  def __init__(self, embed_dim):\n",
    "    super().__init__()\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),nn.Linear(embed_dim, embed_dim))\n",
    "    self.lin_embed = nn.Linear(embed_dim,57)\n",
    "    self.lin1 = nn.Linear(57,57)\n",
    "    self.lin2 = nn.Linear(57, 57)\n",
    "    self.lin3 = nn.Linear(57, 57)\n",
    "    self.lin4 = nn.Linear(57, 57)\n",
    "    self.lin5 = nn.Linear(57,57)\n",
    "    self.act = lambda x : torch.sigmoid(x)\n",
    "    nn.init.normal_(self.lin_embed.weight, mean=0, std=0.2)\n",
    "    nn.init.normal_(self.lin_embed.bias, mean=0, std=0.1)\n",
    "    nn.init.normal_(self.lin1.weight, mean=0, std=0.2)\n",
    "    nn.init.normal_(self.lin1.bias, mean=0, std=0.1)\n",
    "    nn.init.normal_(self.lin2.weight, mean=0, std=0.2)\n",
    "    nn.init.normal_(self.lin2.bias, mean=0, std=0.1)\n",
    "    nn.init.normal_(self.lin3.weight, mean=0, std=0.2)\n",
    "    nn.init.normal_(self.lin3.bias, mean=0, std=0.1)\n",
    "    nn.init.normal_(self.lin4.weight, mean=0, std=0.2)\n",
    "    nn.init.normal_(self.lin4.bias, mean=0, std=0.1)\n",
    "    nn.init.normal_(self.lin5.weight, mean=0, std=0.2)\n",
    "    nn.init.normal_(self.lin5.bias, mean=0, std=0.1)\n",
    "  def forward(self,x,t,L):\n",
    "      # setting the fixed points of x\n",
    "      l = torch.zeros_like(x)\n",
    "      l[:,0] = x[:,0]\n",
    "      l[:,1] = x[:,1]\n",
    "      l[:,2] = -torch.ones_like(x[:,2])*2 + x[:,2]\n",
    "\n",
    "      x = x - l\n",
    "      embed = self.act(self.embed(t))\n",
    "      h = self.lin1(x)\n",
    "      h = h+ self.lin_embed(embed)\n",
    "      h = self.act(self.lin2(h))\n",
    "      #h = self.act(self.lin3(h))\n",
    "      #h = self.act(self.lin4(h))\n",
    "      #h = self.act(self.lin5(h))\n",
    "\n",
    "      # projection\n",
    "      p = torch.unsqueeze(L@ torch.squeeze(h),0)\n",
    "      h = p\n",
    "      # NOT normalizing the output\n",
    "      #h = h/ t[:,None]\n",
    "\n",
    "      # setting the force on the fixed point to zero\n",
    "      l2 = torch.zeros_like(h)\n",
    "      l2[:,0] = h[:,0]\n",
    "      l2[:,1] = h[:,1]\n",
    "      l2[:,2] = -torch.ones_like(h[:,2])*2 + h[:,2]\n",
    "      h = h - l2\n",
    "      return torch.squeeze(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "604203e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = torch.nn.DataParallel(ScoreNet(58))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910be754",
   "metadata": {},
   "source": [
    "## Sampling the reverse SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7790adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.load('train_dataset.npy',allow_pickle=True)\n",
    "numpy_data = np.squeeze(data1)\n",
    "torch_data = torch.tensor(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f97521",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66832359",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def force(x):\n",
    "  return(torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d39b5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(mode = \"max-autotune\")\n",
    "def get_data(data, i, j, save_at, already_in_there=np.array([])):\n",
    "    if len(already_in_there) ==0:\n",
    "        positions =[]\n",
    "    else:\n",
    "        positions = np.ndarray.tolist(already_in_there)\n",
    "    h = 0.01\n",
    "    for x in tqdm(data[i+ len(already_in_there):j]):\n",
    "      q = torch.squeeze(torch.flatten(x))\n",
    "      p = torch.zeros_like(q)\n",
    "      M = torch.eye(len(q))\n",
    "      gs = [length_constraint(i,j,torch.squeeze(q)) for (i,j) in bones2]\n",
    "      gs.append(length_constraint_2(1,torch.squeeze(q)))\n",
    "      gs.append(length_constraint_2(11,torch.squeeze(q)))\n",
    "      gs.append(length_constraint_2(15,torch.squeeze(q)))\n",
    "      qs,_ = gBAOAB_integrator(q,p,force, gs, h,M, 1, 1, 1000,1,10**(-13))\n",
    "      ts = []\n",
    "      for qold in qs:\n",
    "        qnew = qold\n",
    "        qnew[0] = 0\n",
    "        qnew[1] = 0\n",
    "        qnew[2] = 2\n",
    "        ts.append(qnew)\n",
    "      positions.append(ts)\n",
    "      pos_array= np.array(positions)\n",
    "      np.save(save_at, pos_array)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd22221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "already = np.load('t10_1000-2000.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/745 [00:00<?, ?it/s][2023-08-24 20:47:43,588] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT <graph break in get_data> /tmp/ipykernel_1680046/3124810454.py line 8 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tkelly/anaconda3/lib/python3.9/site-packages/tqdm/utils.py\", line 75, in __eq__\n",
      "    return self._comparable == other._comparable\n",
      "AttributeError: 'function' object has no attribute '_comparable'\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "[2023-08-24 20:47:43,786] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  0%|          | 1/745 [02:31<31:17:52, 151.44s/it][2023-08-24 20:50:15,102] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  0%|          | 2/745 [04:52<29:59:16, 145.30s/it][2023-08-24 20:52:36,098] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  0%|          | 3/745 [07:23<30:28:26, 147.85s/it][2023-08-24 20:55:06,993] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|          | 4/745 [09:51<30:26:01, 147.86s/it][2023-08-24 20:57:34,849] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|          | 5/745 [12:15<30:08:05, 146.60s/it][2023-08-24 20:59:59,235] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|          | 6/745 [14:49<30:37:43, 149.21s/it][2023-08-24 21:02:33,491] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|          | 7/745 [17:16<30:23:20, 148.24s/it][2023-08-24 21:04:59,744] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|          | 8/745 [19:47<30:33:38, 149.28s/it][2023-08-24 21:07:31,249] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|          | 9/745 [22:26<31:09:16, 152.39s/it][2023-08-24 21:10:10,464] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|▏         | 10/745 [24:53<30:45:30, 150.65s/it][2023-08-24 21:12:37,250] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  1%|▏         | 11/745 [27:28<30:59:15, 151.98s/it][2023-08-24 21:15:12,237] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  2%|▏         | 12/745 [29:57<30:43:55, 150.94s/it][2023-08-24 21:17:40,779] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  2%|▏         | 13/745 [32:33<31:00:46, 152.52s/it][2023-08-24 21:20:16,952] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  2%|▏         | 14/745 [35:16<31:39:02, 155.87s/it][2023-08-24 21:23:00,571] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  2%|▏         | 15/745 [37:48<31:19:24, 154.47s/it][2023-08-24 21:25:31,796] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  2%|▏         | 16/745 [40:24<31:25:33, 155.19s/it][2023-08-24 21:28:08,655] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  2%|▏         | 17/745 [43:06<31:45:25, 157.04s/it][2023-08-24 21:30:49,991] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  2%|▏         | 18/745 [45:34<31:11:31, 154.46s/it][2023-08-24 21:33:18,450] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 19/745 [48:17<31:38:02, 156.86s/it][2023-08-24 21:36:00,909] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 20/745 [50:49<31:18:16, 155.44s/it][2023-08-24 21:38:33,054] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 21/745 [53:27<31:26:58, 156.38s/it][2023-08-24 21:41:11,604] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 22/745 [56:04<31:23:41, 156.32s/it][2023-08-24 21:43:47,799] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 23/745 [58:32<30:53:22, 154.02s/it][2023-08-24 21:46:16,455] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 24/745 [1:01:12<31:09:36, 155.58s/it][2023-08-24 21:48:55,681] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 25/745 [1:03:48<31:09:10, 155.76s/it][2023-08-24 21:51:31,863] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  3%|▎         | 26/745 [1:06:19<30:50:39, 154.44s/it][2023-08-24 21:54:03,201] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  4%|▎         | 27/745 [1:09:01<31:13:28, 156.56s/it][2023-08-24 21:56:44,712] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  4%|▍         | 28/745 [1:11:37<31:09:43, 156.46s/it][2023-08-24 21:59:20,940] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  4%|▍         | 29/745 [1:14:07<30:44:08, 154.54s/it][2023-08-24 22:01:50,995] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  4%|▍         | 30/745 [1:16:48<31:03:46, 156.40s/it][2023-08-24 22:04:31,751] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  4%|▍         | 31/745 [1:19:26<31:07:19, 156.92s/it][2023-08-24 22:07:09,867] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  4%|▍         | 32/745 [1:21:57<30:43:10, 155.11s/it][2023-08-24 22:09:40,744] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-08-24 22:09:40,820] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)\n",
      "   function: 'G_gs' (/tmp/ipykernel_1680046/2395838894.py:7)\n",
      "   reasons:  ___check_obj_id(gs[0], 140377215852112)\n",
      "to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.\n",
      "  4%|▍         | 33/745 [1:28:57<46:26:09, 234.79s/it][2023-08-24 22:16:41,461] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  5%|▍         | 34/745 [1:35:39<56:17:00, 284.98s/it][2023-08-24 22:23:23,554] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  5%|▍         | 35/745 [1:42:30<63:39:54, 322.81s/it][2023-08-24 22:30:14,626] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  5%|▍         | 36/745 [1:49:29<69:12:45, 351.43s/it][2023-08-24 22:37:12,842] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  5%|▍         | 37/745 [1:56:17<72:29:06, 368.57s/it][2023-08-24 22:44:01,401] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  5%|▌         | 38/745 [2:03:14<75:13:40, 383.06s/it][2023-08-24 22:50:58,257] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  5%|▌         | 39/745 [2:10:07<76:53:27, 392.08s/it][2023-08-24 22:57:51,387] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  5%|▌         | 40/745 [2:17:03<78:11:00, 399.23s/it][2023-08-24 23:04:47,322] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▌         | 41/745 [2:24:04<79:19:03, 405.60s/it][2023-08-24 23:11:47,777] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▌         | 42/745 [2:30:48<79:08:18, 405.26s/it][2023-08-24 23:18:32,251] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▌         | 43/745 [2:37:36<79:09:40, 405.96s/it][2023-08-24 23:25:19,830] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▌         | 44/745 [2:44:16<78:43:23, 404.28s/it][2023-08-24 23:32:00,205] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▌         | 45/745 [2:51:04<78:48:22, 405.29s/it][2023-08-24 23:38:47,850] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▌         | 46/745 [2:57:49<78:40:11, 405.17s/it][2023-08-24 23:45:32,722] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▋         | 47/745 [3:04:26<78:07:11, 402.91s/it][2023-08-24 23:52:10,369] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  6%|▋         | 48/745 [3:11:10<78:02:59, 403.13s/it][2023-08-24 23:58:54,003] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  7%|▋         | 49/745 [3:17:51<77:49:06, 402.51s/it][2023-08-25 00:05:35,069] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  7%|▋         | 50/745 [3:24:38<77:59:54, 404.02s/it][2023-08-25 00:12:22,622] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  7%|▋         | 51/745 [3:31:27<78:07:37, 405.27s/it][2023-08-25 00:19:10,798] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  7%|▋         | 52/745 [3:38:10<77:55:09, 404.78s/it][2023-08-25 00:25:54,422] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  7%|▋         | 53/745 [3:45:03<78:17:14, 407.28s/it][2023-08-25 00:32:47,549] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  7%|▋         | 54/745 [3:51:59<78:38:50, 409.74s/it][2023-08-25 00:39:43,024] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  7%|▋         | 55/745 [3:58:50<78:38:24, 410.30s/it][2023-08-25 00:46:34,618] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 56/745 [4:05:50<79:05:08, 413.22s/it][2023-08-25 00:53:34,655] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 57/745 [4:13:04<80:07:26, 419.25s/it][2023-08-25 01:00:57,664] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 58/745 [4:20:42<82:12:50, 430.82s/it][2023-08-25 01:08:25,807] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 59/745 [4:27:59<82:29:36, 432.91s/it][2023-08-25 01:15:43,577] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 60/745 [4:34:53<81:16:10, 427.11s/it][2023-08-25 01:22:37,174] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 61/745 [4:41:31<79:28:20, 418.28s/it][2023-08-25 01:29:14,831] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 62/745 [4:48:26<79:11:56, 417.45s/it][2023-08-25 01:36:10,329] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  8%|▊         | 63/745 [4:55:00<77:44:13, 410.34s/it][2023-08-25 01:42:44,099] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "  9%|▊         | 64/745 [5:01:46<77:24:02, 409.17s/it][2023-08-25 01:49:30,444] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)\n",
      "   function: 'gBAOAB_step_exact' (/tmp/ipykernel_1680046/3710533717.py:1)\n",
      "   reasons:  ___check_obj_id(gs[0], 140377215852112)\n",
      "to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.\n",
      "[2023-08-25 01:49:30,452] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)\n",
      "   function: 'J' (/tmp/ipykernel_1680046/2395838894.py:15)\n",
      "   reasons:  ___check_obj_id(gs[0], 140377215852112)\n",
      "to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.\n",
      "[2023-08-25 01:49:30,489] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)\n",
      "   function: 'rattle_step' (/tmp/ipykernel_1680046/3769212027.py:1)\n",
      "   reasons:  ___check_obj_id(gs[0], 140377215852112)\n",
      "to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.\n",
      " 43%|████▎     | 317/745 [35:43:19<54:43:21, 460.28s/it]"
     ]
    }
   ],
   "source": [
    "qs = get_data(torch_data,1000,2000,'t10_1000-2000.npy', already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389286cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.load('t10_0-1000.npy', allow_pickle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f650b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
