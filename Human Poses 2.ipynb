{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import c3d\n",
    "import mat4py\n",
    "import functools\n",
    "import scipy.io\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from tqdm import notebook\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import math\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "device ='cpu'\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.autograd.functional import jacobian, hessian\n",
    "torch.set_default_dtype(torch.double)\n",
    "from ipynb.fs.defs.gBAOAB import gBAOAB_integrator, gBAOAB_integrator_mass, gBAOAB_step_exact\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "import random\n",
    "from torchmin import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('C:\\\\Users\\\\Desktop\\\\Thesis\\\\HumanEval\\\\S2\\\\Mocap_Data\\\\Walking_1.mat')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[-431.09890747,  323.9395752 ,  995.49688721],\n        [-198.52206421,  280.0027771 , 1094.01745605],\n        [-270.77734375,  195.53082275, 1024.84570312],\n        ...,\n        [   0.        ,    0.        ,    0.        ],\n        [   0.        ,    0.        ,    0.        ],\n        [   0.        ,    0.        ,    0.        ]],\n\n       [[-434.81082153,  322.97921753,  996.29925537],\n        [-199.78430176,  281.39175415, 1095.79394531],\n        [-268.5760498 ,  195.46652222, 1025.36669922],\n        ...,\n        [   0.        ,    0.        ,    0.        ],\n        [   0.        ,    0.        ,    0.        ],\n        [   0.        ,    0.        ,    0.        ]],\n\n       [[-438.90246582,  321.10977173,  997.38763428],\n        [-201.00534058,  282.6975708 , 1097.75732422],\n        [-266.43099976,  195.89286804, 1026.08081055],\n        ...,\n        [   0.        ,    0.        ,    0.        ],\n        [   0.        ,    0.        ,    0.        ],\n        [   0.        ,    0.        ,    0.        ]],\n\n       ...,\n\n       [[-428.49890137, -443.31906128,  994.77215576],\n        [-514.11340332, -180.5887146 , 1107.90588379],\n        [-417.0645752 , -180.02392578, 1022.33319092],\n        ...,\n        [   0.        ,    0.        ,    0.        ],\n        [-549.98468018, -452.36300659,  979.48913574],\n        [-549.98468018, -452.36300659,    0.        ]],\n\n       [[-423.39819336, -445.62585449,  995.62567139],\n        [-510.11663818, -184.31913757, 1107.54833984],\n        [-412.17480469, -184.88442993, 1022.60925293],\n        ...,\n        [   0.        ,    0.        ,    0.        ],\n        [-546.1965332 , -455.84677124,  980.15887451],\n        [-546.1965332 , -455.84677124,    0.        ]],\n\n       [[-418.31082153, -447.37390137,  996.09320068],\n        [-505.85452271, -187.87687683, 1107.00952148],\n        [-407.06359863, -190.03414917, 1022.6907959 ],\n        ...,\n        [   0.        ,    0.        ,    0.        ],\n        [-542.56329346, -459.32705688,  980.82653809],\n        [-542.56329346, -459.32705688,    0.        ]]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['Markers']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Clavicle'], dtype='<U8')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['ParameterGroup'][0][2][2][0][10][2][0][35]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-506.78799438,  -51.61029434,  805.42022705])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['Markers'][1806][38]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ['Left ASIS'] \n",
      "1: ['Left elbow'] \n",
      "2: ['Left forearm (optional alternative anti-sym)'] \n",
      "3: ['Left wrist bar pinkie side (alternative pair 1)'] \n",
      "4: ['Left wrist bar thumb side (alternative pair 1)'] \n",
      "5: ['Right ASIS'] \n",
      "6: ['Left finger'] \n",
      "7: ['Upper back'] \n",
      "8: ['Right elbow'] \n",
      "9: ['Right upper arm (optional alternative anti-sym)'] \n",
      "10: ['Right wrist bar pinkie side (alternative pair 1)'] \n",
      "11: ['Right finger'] \n",
      "12: ['Left knee'] \n",
      "13: ['Right back (optional alternative anti-sym)'] \n",
      "14: ['Left shoulder'] \n",
      "15: ['Right knee'] \n",
      "16: ['Back of neck'] \n",
      "17: ['Right shoulder'] \n",
      "18: ['Right tibial wand marker'] \n",
      "19: ['Left tibial wand marker'] \n",
      "20: ['Left back head'] \n",
      "21: ['Right back head'] \n",
      "22: ['Left front head'] \n",
      "23: ['Right front head'] \n",
      "24: ['Left heel'] \n",
      "25: ['Left ankle'] \n",
      "26: ['Left toe (2nd metatarsel head)'] \n",
      "27: ['Right ankle'] \n",
      "28: ['Right heel'] \n",
      "29: ['Right toe (2nd metatarsel head)'] \n",
      "30: ['Right PSIS'] \n",
      "31: ['Right wrist bar thumb side (alternative pair 1)'] \n",
      "32: ['Sternum'] \n",
      "33: ['Left upper arm (optional alternative anti-sym)'] \n",
      "34: ['Right thigh wand marker'] \n",
      "35: ['Clavicle'] \n",
      "36: ['Left PSIS'] \n",
      "37: ['Right forearm (optional alternative anti-sym)'] \n",
      "38: ['Left thigh wand marker'] \n"
     ]
    }
   ],
   "source": [
    "joints = [0,1,3,5,8,10,12,14,15,17,25,27,32,35,22,23]\n",
    "indices = range(0,39)\n",
    "for i in range(len(indices)):\n",
    "    print(f\"{i}: {mat['ParameterGroup'][0][2][2][0][10][2][0][i]} \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# note - I should sort these\n",
    "#indices = range(0,39)\n",
    "# transforming\n",
    "transform = np.zeros((39,3))\n",
    "for i in range(39):\n",
    "    transform[i][2] = 1\n",
    "\n",
    "train_dataset = []\n",
    "for i in range(len(mat['Markers'])//2):\n",
    "  data = [mat['Markers'][i][j] for j in indices]\n",
    "  train_dataset.append(torch.tensor(np.array(data)+transform, dtype =torch.double).unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "\n",
    "for i in range(len(mat['Markers'])//2, len(mat['Markers'])):\n",
    "  data = [mat['Markers'][i][j] for j in indices]\n",
    "  test_dataset.append(torch.tensor(np.array(data)+transform, dtype =torch.double).unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train_data = np.array([d.numpy() for d in train_dataset])\n",
    "test_data = np.array([d.numpy() for d in test_dataset])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "list = np.transpose(np.array([data[0].flatten().numpy() for data in train_dataset]))\n",
    "\n",
    "# # Create a PCA object\n",
    "# pca = PCA()  # Specify the number of components you want to retain\n",
    "#\n",
    "# pca_result = pca.fit_transform(list)\n",
    "# eigenposes = np.transpose(pca.components_)\n",
    "# eigenvalues = pca.explained_variance_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 39, 3])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(117, 948)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "U, S,_=np.linalg.svd(list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "eigenposes = np.transpose(U)\n",
    "eigenvalues = S"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Projections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "train_data = np.array([d.numpy() for d in train_dataset])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "1691.377197265625"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "-1145.9652099609375"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.min()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# getting the average pose\n",
    "avg_pose = np.squeeze(train_data.mean(axis=0))\n",
    "avg_pose = np.ndarray.flatten(avg_pose)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.05234848e+01, -9.75135418e+01,  9.93005519e+02],\n       [ 1.81891002e+01, -8.01991132e+01,  1.09734191e+03],\n       [ 2.06319369e+01, -9.40360743e+01,  1.03622893e+03],\n       [ 2.44225704e+01, -8.96347777e+01,  8.66264727e+02],\n       [ 1.11231989e+01, -1.05407768e+02,  9.06995790e+02],\n       [-3.30211723e+01, -8.83074704e+01,  1.01229484e+03],\n       [ 1.77338899e+01, -1.01651113e+02,  8.43746180e+02],\n       [-5.84129434e+00, -6.09202360e+01,  1.25282430e+03],\n       [-4.27508576e+01, -5.27883308e+01,  1.10323775e+03],\n       [-4.70981177e+01, -6.13500123e+01,  1.22599984e+03],\n       [-6.50190309e+01, -6.44388580e+01,  8.63607886e+02],\n       [-6.71726576e+01, -7.51322394e+01,  8.43437988e+02],\n       [-3.45383179e+00, -8.61751637e+01,  5.16346356e+02],\n       [-1.50537029e+01, -5.69759235e+01,  1.38266730e+03],\n       [ 9.30007439e+00, -9.08573692e+01,  1.46598217e+03],\n       [-3.71105452e+01, -6.75618415e+01,  5.16885675e+02],\n       [-1.08104832e+01, -7.26948328e+01,  1.51782321e+03],\n       [-3.82709227e+01, -6.75724573e+01,  1.45386538e+03],\n       [-3.69367423e+01, -6.01737110e+01,  3.94745195e+02],\n       [-4.92253170e+00, -7.77228588e+01,  2.73293653e+02],\n       [-5.70524119e+00, -7.93262049e+01,  1.63848714e+03],\n       [-2.14081887e+01, -7.65762522e+01,  1.64007843e+03],\n       [-5.10263826e+00, -9.70988841e+01,  1.66773866e+03],\n       [-2.53112688e+01, -9.61503848e+01,  1.67425833e+03],\n       [-1.25262412e+01, -6.18753091e+01,  1.20041603e+02],\n       [-6.74024583e+00, -7.21916892e+01,  1.17192687e+02],\n       [-2.01693584e+01, -8.90629896e+01,  6.72693686e+01],\n       [-3.04995873e+01, -5.10313946e+01,  1.30238749e+02],\n       [-1.86761523e+01, -4.77559665e+01,  1.09709414e+02],\n       [-4.32757622e+01, -7.34258616e+01,  6.86431939e+01],\n       [-1.33569405e+01, -6.06090763e+01,  1.02160055e+03],\n       [-6.10307498e+01, -8.08354652e+01,  9.11084705e+02],\n       [-1.95614239e+01, -9.70892710e+01,  1.25842782e+03],\n       [ 1.83894988e+01, -9.26777502e+01,  1.29225748e+03],\n       [-3.91530443e+01, -7.16993507e+01,  7.39626258e+02],\n       [-1.70073701e+01, -9.40578730e+01,  1.37899650e+03],\n       [ 3.86738899e-01, -6.72217140e+01,  1.01232327e+03],\n       [-5.68567808e+01, -7.45465309e+01,  9.46086785e+02],\n       [ 8.67958919e+00, -9.41392242e+01,  8.04885765e+02]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pose.reshape(39,3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def length_constraint(i,j, init):\n",
    "    def constraint_fn(x):\n",
    "        return (x[3*i]- x[3*j])**2 +(x[3*i+1]- x[3*j+1])**2 + (x[3*i+2]- x[3*j+2])**2 - ((init[3*i]- init[3*j])**2 +(init[3*i+1]- init[3*j+1])**2 + (init[3*i+2]- init[3*j+2])**2)\n",
    "    return constraint_fn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ['Left ASIS'] \n",
      "1: ['Left elbow'] \n",
      "2: ['Left wrist bar pinkie side (alternative pair 1)'] \n",
      "3: ['Right ASIS'] \n",
      "4: ['Right elbow'] \n",
      "5: ['Right wrist bar pinkie side (alternative pair 1)'] \n",
      "6: ['Left knee'] \n",
      "7: ['Left shoulder'] \n",
      "8: ['Right knee'] \n",
      "9: ['Right shoulder'] \n",
      "10: ['Left ankle'] \n",
      "11: ['Right ankle'] \n",
      "12: ['Sternum'] \n",
      "13: ['Clavicle'] \n",
      "14: ['Left front head'] \n",
      "15: ['Right front head'] \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(joints)):\n",
    "    print(f\"{i}: {mat['ParameterGroup'][0][2][2][0][10][2][0][joints[i]]} \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from numpy import linalg as la"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def isPD(B):\n",
    "    \"\"\"Returns true when input is positive-definite, via Cholesky\"\"\"\n",
    "    try:\n",
    "        _ = la.cholesky(B)\n",
    "        return True\n",
    "    except la.LinAlgError:\n",
    "        return False\n",
    "\n",
    "def nearestPD(A):\n",
    "    \"\"\"Find the nearest positive-definite matrix to input\n",
    "    A Python/Numpy port of John D'Errico's `nearestSPD` MATLAB code [1], which\n",
    "    credits [2].\n",
    "    [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd\n",
    "    [2] N.J. Higham, \"Computing a nearest symmetric positive semidefinite\n",
    "    matrix\" (1988): https://doi.org/10.1016/0024-3795(88)90223-6\n",
    "    \"\"\"\n",
    "\n",
    "    B = (A + A.T) / 2\n",
    "    _, s, V = la.svd(B)\n",
    "\n",
    "    H = np.dot(V.T, np.dot(np.diag(s), V))\n",
    "\n",
    "    A2 = (B + H) / 2\n",
    "\n",
    "    A3 = (A2 + A2.T) / 2\n",
    "\n",
    "    if isPD(A3):\n",
    "        return A3\n",
    "\n",
    "    spacing = np.spacing(la.norm(A))\n",
    "    # The above is different from [1]. It appears that MATLAB's `chol` Cholesky\n",
    "    # decomposition will accept matrixes with exactly 0-eigenvalue, whereas\n",
    "    # Numpy's will not. So where [1] uses `eps(mineig)` (where `eps` is Matlab\n",
    "    # for `np.spacing`), we use the above definition. CAVEAT: our `spacing`\n",
    "    # will be much larger than [1]'s `eps(mineig)`, since `mineig` is usually on\n",
    "    # the order of 1e-16, and `eps(1e-16)` is on the order of 1e-34, whereas\n",
    "    # `spacing` will, for Gaussian random matrixes of small dimension, be on\n",
    "    # othe order of 1e-16. In practice, both ways converge, as the unit test\n",
    "    # below suggests.\n",
    "    I = np.eye(A.shape[0])\n",
    "    k = 1\n",
    "    while not isPD(A3):\n",
    "        mineig = np.min(np.real(la.eigvals(A3)))\n",
    "        A3 += I * (-mineig * k**2 + spacing)\n",
    "        k += 1\n",
    "\n",
    "    return A3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# note - using NearPD from Higham"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running Evaluation Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def avg_j2j(frame1,frame2):\n",
    "    dists = []\n",
    "    frame_1 = np.array(frame1)\n",
    "    frame_2 = np.array(frame2)\n",
    "    for i in range(len(joints)):\n",
    "        d = math.dist(frame_1[joints[i]], frame_2[joints[i]])\n",
    "        dists.append(d)\n",
    "    return np.mean(dists)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def blank(x):\n",
    "    t = x[0]\n",
    "    return torch.tensor([0.0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "h = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "IntProgress(value=0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c51a4b9255d44b9839bd566491f84dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diffs = []\n",
    "\n",
    "f = IntProgress(min=0, max=len(test_dataset[0:100]))\n",
    "display(f)\n",
    "for frame1 in test_dataset[0:100]:\n",
    "\n",
    "    frame = torch.squeeze(frame1)\n",
    "\n",
    "    M = torch.eye(39*3)\n",
    "\n",
    "\n",
    "    # initialising from a random training pose\n",
    "    x_init = torch.flatten(train_dataset[random.randint(0,len(train_dataset))])\n",
    "    v_init = torch.zeros_like(x_init)\n",
    "\n",
    "    # defining the constraints\n",
    "    #wrist_elbow_l = length_constraint(joints[1],joints[2],x_init)\n",
    "    wrist_elbow_l = length_constraint(joints[1],joints[2],x_init)\n",
    "    elbow_shoulder_l = length_constraint(joints[1],joints[7],x_init)\n",
    "    wrist_elbow_r = length_constraint(joints[5],joints[4],x_init)\n",
    "    elbow_shoulder_r= length_constraint(joints[4],joints[9],x_init)\n",
    "\n",
    "    knee_ankle_l = length_constraint(joints[6],joints[10],x_init)\n",
    "    knee_ankle_r = length_constraint(joints[8],joints[11],x_init)\n",
    "\n",
    "    knee_asis_l = length_constraint(joints[6],joints[0],x_init)\n",
    "    knee_asis_r = length_constraint(joints[8],joints[3],x_init)\n",
    "\n",
    "    shoulder_clav_l = length_constraint(joints[13],joints[7],x_init)\n",
    "    shoulder_clav_r = length_constraint(joints[13],joints[9],x_init)\n",
    "\n",
    "    #stern_clav_l = length_constraint(joints[12],joints[13],x_init)\n",
    "\n",
    "    gs = [wrist_elbow_l,wrist_elbow_r,elbow_shoulder_l,elbow_shoulder_r,knee_ankle_l, knee_ankle_r,shoulder_clav_l,shoulder_clav_r] #,knee_asis_l, knee_asis_r] #,shoulder_clav_l,shoulder_clav_r,stern_clav_l]\n",
    "\n",
    "    # defining and randomly perturbing the image\n",
    "    fx = 1.0\n",
    "    fy = 1.0\n",
    "    cx = 0\n",
    "    cy = 0\n",
    "    a1 = torch.tensor([[fx], [0], [cx]], dtype=torch.double)\n",
    "    a2 = torch.tensor([[0], [fy], [cy]], dtype=torch.double)\n",
    "    a3 = torch.tensor([[0],[0],[1]], dtype=torch.double)\n",
    "    i1 = frame @ a1\n",
    "    i2 = frame @ a2\n",
    "    i3 = frame @ a3\n",
    "\n",
    "    image = torch.hstack([i1/i3, i2/i3])\n",
    "\n",
    "\n",
    "    #image += torch.randn_like(image)* (torch.randint(11, size = (1,)))\n",
    "\n",
    "    # need to re-define density, force and mass to use the new image\n",
    "    def neg_log_density(pose2):\n",
    "        pose = pose2.reshape((39,3))\n",
    "\n",
    "        transform = torch.zeros((39,3))\n",
    "        for i in range(39):\n",
    "            transform[i][2] = 1\n",
    "\n",
    "        pose = torch.squeeze(pose) + transform\n",
    "        fx = 1.0\n",
    "        fy = 1.0\n",
    "        cx = 0\n",
    "        cy = 0\n",
    "        a1 = torch.tensor([[fx], [0], [cx]], dtype=torch.double)\n",
    "        a2 = torch.tensor([[0], [fy], [cy]], dtype=torch.double)\n",
    "        a3 = torch.tensor([[0],[0],[1]], dtype=torch.double)\n",
    "\n",
    "        # Map the 3D point to 2D point\n",
    "        p1 = pose@ a1\n",
    "        p2 = pose @ a2\n",
    "        p3 = pose @ a3\n",
    "\n",
    "        projection = torch.hstack([p1/p3, p2/p3])\n",
    "\n",
    "        n = projection - image\n",
    "        #print(n)\n",
    "        # note - taking the variance to be 1...\n",
    "        pi = torch.tensor([0.], requires_grad=True)\n",
    "        for point in n:\n",
    "            pi = pi+ torch.linalg.norm(point)**2 / 36.36\n",
    "\n",
    "        p2 = torch.flatten(pose)\n",
    "        for i in range(len(eigenvalues)):\n",
    "            pi = pi+ (torch.dot(torch.tensor(eigenposes[i]),(p2-torch.tensor(avg_pose)))**2 / eigenvalues[i])\n",
    "        return pi\n",
    "\n",
    "    def force(x):\n",
    "        #print(\"x = \",x)\n",
    "        #print(\"force = \",torch.squeeze(jacobian(neg_log_density, x), dim = 0))\n",
    "        return torch.squeeze(jacobian(neg_log_density, x), dim = 0)\n",
    "\n",
    "\n",
    "    positions, velocities = gBAOAB_integrator(x_init,v_init, force,gs, h,M, .001, 1, 500)\n",
    "\n",
    "    # getting the mean position\n",
    "    mean = torch.tensor(np.array(torch.stack(positions[100:])).mean(axis=0))\n",
    "\n",
    "    # getting mean difference between this and the pose\n",
    "    jd = avg_j2j(mean.reshape((39,3)),frame)\n",
    "    print(\"GBAOAB: \", jd)\n",
    "    diffs.append(jd)\n",
    "\n",
    "    # BFGS\n",
    "    result = minimize(neg_log_density, x_init, method='bfgs')\n",
    "    jd2 = avg_j2j(result.x.reshape((39,3)),frame)\n",
    "    print(\"BFGS: \", jd2)\n",
    "\n",
    "    print(f\"Average joint movement: {mean.mean()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "velocities_1 = [vel[0] for vel in velocities]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forces_1 = [force(x)[0] for x in positions]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(velocities_1, label = \"Velocities\")\n",
    "plt.plot(forces_1, label = \"Force\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "velocities_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_init.reshape((39,3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# defining and randomly perturbing the image\n",
    "fx = 1.0\n",
    "fy = 1.0\n",
    "cx = 0\n",
    "cy = 0\n",
    "a1 = torch.tensor([[fx], [0], [cx]], dtype=torch.double)\n",
    "a2 = torch.tensor([[0], [fy], [cy]], dtype=torch.double)\n",
    "a3 = torch.tensor([[0],[0],[1]], dtype=torch.double)\n",
    "i1 = frame @ a1\n",
    "i2 = frame @ a2\n",
    "i3 = frame @ a3\n",
    "\n",
    "image = torch.hstack([i1/i3, i2/i3])\n",
    "\n",
    "\n",
    "image += torch.randn_like(image)* (torch.randint(11, size = (1,)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_initial(x):\n",
    "        pose = x.reshape((39,3))\n",
    "\n",
    "        transform = torch.zeros((39,3))\n",
    "        for i in range(39):\n",
    "            transform[i][2] = 1\n",
    "\n",
    "        pose = torch.squeeze(pose) + transform\n",
    "\n",
    "        fx = 1.0\n",
    "        fy = 1.0\n",
    "        cx = 0\n",
    "        cy = 0\n",
    "        a1 = torch.tensor([[fx], [0], [cx]], dtype=torch.double)\n",
    "        a2 = torch.tensor([[0], [fy], [cy]], dtype=torch.double)\n",
    "        a3 = torch.tensor([[0],[0],[1]], dtype=torch.double)\n",
    "\n",
    "        # Map the 3D point to 2D point\n",
    "        p1 = pose@ a1\n",
    "        p2 = pose @ a2\n",
    "        p3 = pose @ a3\n",
    "\n",
    "        projection = torch.hstack([p1/p3, p2/p3])\n",
    "\n",
    "        n = projection - image\n",
    "        print(n)\n",
    "        # note - taking the variance to be 1...\n",
    "        pi = torch.tensor([0.], requires_grad=True)\n",
    "        for point in n:\n",
    "            pi = pi+ torch.linalg.norm(point)**2\n",
    "        return pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jacobian(test_initial, x_init)[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def testing2(x):\n",
    "    '''computing the sum over i of eigenpose[i]^T (x - avg_pose)^2 / eigenval[i]'''\n",
    "    pi = torch.tensor([0.0], requires_grad=True)\n",
    "    for i in range(len(eigenvalues)):\n",
    "        pi = pi+ (torch.dot(torch.tensor(eigenposes[i]),(x-torch.tensor(avg_pose)))**2 / eigenvalues[i])\n",
    "    return pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def deriv_test(x):\n",
    "    j =0\n",
    "    deriv = 2*eigenposes[j][0]*(2*x[0] - 2* avg_pose[0])\n",
    "    for i in range(1,len(x)):\n",
    "        deriv += eigenposes[j][i]*(2*x[i] - 2* avg_pose[i])\n",
    "    return deriv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing2(x_init)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jacobian(testing2, x_init)[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deriv_test(x_init)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#math.dist(positions[0].reshape((39,3))[1],positions[0].reshape((39,3))[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "second = [torch.tensor([pos[9], pos[10],pos[11]]) for pos in positions]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_init = torch.flatten(train_dataset[random.randint(0,len(train_dataset))]).reshape((39,3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_init.reshape((39,3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positions[199].reshape((39,3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pose = positions[199].reshape((39,3))\n",
    "pose = torch.squeeze(pose) + transform\n",
    "fx = 1.0\n",
    "fy = 1.0\n",
    "cx = 0\n",
    "cy = 0\n",
    "a1 = torch.tensor([[fx], [0], [cx]], dtype=torch.double)\n",
    "a2 = torch.tensor([[0], [fy], [cy]], dtype=torch.double)\n",
    "a3 = torch.tensor([[0],[0],[1]], dtype=torch.double)\n",
    "\n",
    "# Map the 3D point to 2D point\n",
    "p1 = pose@ a1\n",
    "p2 = pose @ a2\n",
    "p3 = pose @ a3\n",
    "\n",
    "projection = torch.hstack([p1/p3, p2/p3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "projection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frame1 = torch.squeeze(frame1)\n",
    "# Map the 3D point to 2D point\n",
    "p1 = frame1 @ a1\n",
    "p2 = frame1 @ a2\n",
    "p3 = frame1 @ a3\n",
    "\n",
    "projection = torch.hstack([p1/p3, p2/p3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "projection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using different masses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "h = .5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "IntProgress(value=0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcb2d1fdb34948bc962e143b55bc54d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "i = 0\n",
    "std =1\n",
    "diffs = []\n",
    "diffs1 = []\n",
    "diffs_bfgs = []\n",
    "f = IntProgress(min=0, max=len(test_dataset[0:100]))\n",
    "display(f)\n",
    "for frame1 in test_dataset[0:100]:\n",
    "    i +=1\n",
    "\n",
    "    frame = torch.squeeze(frame1)\n",
    "    #print(\"Target: \",frame.reshape(39,3))\n",
    "\n",
    "    M = torch.eye(39*3)\n",
    "\n",
    "\n",
    "\n",
    "    # initialising from a random training pose\n",
    "    x_init = torch.flatten(train_dataset[random.randint(0,len(train_dataset))-1])\n",
    "    #print(\"Init: \",x_init.reshape(39,3))\n",
    "    v_init = torch.zeros_like(x_init)\n",
    "\n",
    "    # defining the constraints\n",
    "    #wrist_elbow_l = length_constraint(joints[1],joints[2],x_init)\n",
    "    wrist_elbow_l = length_constraint(joints[1],joints[2],x_init)\n",
    "    elbow_shoulder_l = length_constraint(joints[1],joints[7],x_init)\n",
    "    wrist_elbow_r = length_constraint(joints[5],joints[4],x_init)\n",
    "    elbow_shoulder_r= length_constraint(joints[4],joints[9],x_init)\n",
    "\n",
    "    knee_ankle_l = length_constraint(joints[6],joints[10],x_init)\n",
    "    knee_ankle_r = length_constraint(joints[8],joints[11],x_init)\n",
    "\n",
    "    knee_asis_l = length_constraint(joints[6],joints[0],x_init)\n",
    "    knee_asis_r = length_constraint(joints[8],joints[3],x_init)\n",
    "\n",
    "    shoulder_clav_l = length_constraint(joints[13],joints[7],x_init)\n",
    "    shoulder_clav_r = length_constraint(joints[13],joints[9],x_init)\n",
    "\n",
    "    #stern_clav_l = length_constraint(joints[12],joints[13],x_init)\n",
    "\n",
    "    gs = [wrist_elbow_l,wrist_elbow_r,elbow_shoulder_l,elbow_shoulder_r,knee_ankle_l, knee_ankle_r]#,shoulder_clav_l,shoulder_clav_r] #,knee_asis_l, knee_asis_r] #,shoulder_clav_l,shoulder_clav_r,stern_clav_l]\n",
    "\n",
    "    # defining and randomly perturbing the image\n",
    "    fx = 1.0\n",
    "    fy = 1.0\n",
    "    cx = 0\n",
    "    cy = 0\n",
    "    a1 = torch.tensor([[fx], [0], [cx]], dtype=torch.double)\n",
    "    a2 = torch.tensor([[0], [fy], [cy]], dtype=torch.double)\n",
    "    a3 = torch.tensor([[0],[0],[1]], dtype=torch.double)\n",
    "    i1 = frame @ a1\n",
    "    i2 = frame @ a2\n",
    "    i3 = frame @ a3\n",
    "\n",
    "    image = torch.hstack([i1/i3, i2/i3])\n",
    "\n",
    "\n",
    "    image += torch.randn_like(image)*std\n",
    "\n",
    "    # need to re-define density, force and mass to use the new image\n",
    "    def neg_log_density(pose2):\n",
    "        pose = pose2.reshape((39,3))\n",
    "\n",
    "        transform = torch.zeros((39,3))\n",
    "        for i in range(39):\n",
    "            transform[i][2] = 1\n",
    "\n",
    "        pose = torch.squeeze(pose) + transform\n",
    "        fx = 1.0\n",
    "        fy = 1.0\n",
    "        cx = 0\n",
    "        cy = 0\n",
    "        a1 = torch.tensor([[fx], [0], [cx]], dtype=torch.double)\n",
    "        a2 = torch.tensor([[0], [fy], [cy]], dtype=torch.double)\n",
    "        a3 = torch.tensor([[0],[0],[1]], dtype=torch.double)\n",
    "\n",
    "        # Map the 3D point to 2D point\n",
    "        p1 = pose@ a1\n",
    "        p2 = pose @ a2\n",
    "        p3 = pose @ a3\n",
    "\n",
    "        projection = torch.hstack([p1/p3, p2/p3])\n",
    "\n",
    "        n = projection - image\n",
    "        #print(n)\n",
    "        # note - taking the variance to be 1...\n",
    "        pi = torch.tensor([0.], requires_grad=True)\n",
    "        for point in n:\n",
    "            pi = pi+ torch.linalg.norm(point)**2 / std\n",
    "\n",
    "        p2 = torch.flatten(pose)\n",
    "        for i in range(len(eigenvalues)):\n",
    "            pi = pi+ (torch.dot(torch.tensor(eigenposes[i]),(p2-torch.tensor(avg_pose)))**2 / eigenvalues[i]**2)\n",
    "        return pi\n",
    "\n",
    "    def force(x):\n",
    "        #print(\"x = \",x)\n",
    "        #print(\"force = \",torch.squeeze(jacobian(neg_log_density, x), dim = 0))\n",
    "        return torch.tensor([1.])*torch.squeeze(jacobian(neg_log_density, x), dim = 0)\n",
    "\n",
    "    def mass(x):\n",
    "        #print(torch.tensor(nearestPD(hessian(neg_log_density, x).numpy())).mean())\n",
    "        return torch.tensor(nearestPD(hessian(neg_log_density, x).numpy()))\n",
    "\n",
    "    #positions, velocities = gBAOAB_integrator_mass(x_init,v_init, force,gs, h,mass, 1, 1,200)\n",
    "    positions, velocities = gBAOAB_integrator(x_init,v_init, force,gs, h,M, 1, 1, 100)\n",
    "\n",
    "    densities = [neg_log_density(p).detach().numpy() for p in positions]\n",
    "    plt.plot(densities,label = f\"Frame {i}\")\n",
    "    plt.show()\n",
    "    forces = [force(p) for p in positions]\n",
    "    # getting the mean position\n",
    "    mean = torch.tensor(np.array(torch.stack(positions[50:])).mean(axis=0))\n",
    "    #mean1 =torch.tensor(np.array(torch.stack(positions1[50:])).mean(axis=0))\n",
    "    # getting mean difference between this and the pose\n",
    "    jd = avg_j2j(mean.reshape((39,3)),frame)\n",
    "    print(\"GBAOAB (varied mass): \", jd)\n",
    "    diffs.append(jd)\n",
    "    #jd1 = avg_j2j(mean1.reshape((39,3)),frame)\n",
    "    #print(\"GBAOAB (constant mass): \", jd1)\n",
    "    #diffs1.append(jd1)\n",
    "\n",
    "    # BFGS\n",
    "    #result = minimize(neg_log_density, x_init, method='bfgs')\n",
    "    #jd2 = avg_j2j(result.x.reshape((39,3)),frame)\n",
    "    #print(\"BFGS: \", jd2)\n",
    "    diffs_bfgs.append(jd2)\n",
    "    print(f\"Average joint movement: {avg_j2j(mean.reshape((39,3)), x_init.detach().reshape((39,3)))}\")\n",
    "    #print(f\"Average joint movement - constant mass: {mean1.mean()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "densities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forces1 = [torch.linalg.norm(f) for f in forces]\n",
    "forces1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forces[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forces[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
